{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports & Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note 1.\n",
    "hiefData = \\\n",
    "    pd.read_csv(r'..\\data\\hiefData.csv', comment='#')\n",
    "usVeteransFKBP5 = \\\n",
    "    pd.read_csv(r'..\\data\\usVeteransFKBP5.csv', comment='#')\n",
    "ptsdWorldMentalHealthSurvey = \\\n",
    "    pd.read_csv(r'..\\data\\ptsdWorldMentalHealthSurvey.csv', comment='#')\n",
    "healthCarePriceIndex = \\\n",
    "    pd.read_csv(r'..\\data\\healthCarePriceIndex.csv', comment='#')\n",
    "## Note 2.\n",
    "rs1360780Data = \\\n",
    "    pd.read_csv(r'..\\data\\rs1360780_frequency.tsv', sep='\\t', \n",
    "                skiprows=12, header=0).drop(columns=['#Study'])\n",
    "rs3800373Data = \\\n",
    "    pd.read_csv(r'..\\data\\rs3800373_frequency.tsv', sep='\\t',\n",
    "                skiprows=12, header=0).drop(columns=['#Study'])\n",
    "rs9296158Data = \\\n",
    "    pd.read_csv(r'..\\data\\rs9296158_frequency.tsv', sep='\\t',\n",
    "                skiprows=12, header=0).drop(columns=['#Study'])\n",
    "rs9470080Data = \\\n",
    "    pd.read_csv(r'..\\data\\rs9470080_frequency.tsv', sep='\\t',\n",
    "                skiprows=12, header=0).drop(columns=['#Study'])\n",
    "## Note 3.\n",
    "WorldValuesSurveyData = \\\n",
    "    pd.read_csv(r'..\\data\\WVS_Cross-National_Wave_7_inverted_csv_v6_0.csv', \n",
    "                low_memory=False).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applied Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "countryScope = {\n",
    "    \"COL\": [\"Colombia\", \"Colombia (Medellin)\"],\n",
    "    \"IRQ\": [\"Iraq\"],\n",
    "    \"PER\": [\"Peru\"],\n",
    "    \"CHN\": [\"PRC China\", \"China\"],\n",
    "    \"UKR\": [\"Ukraine\"],\n",
    "    \"BRA\": [\"Brazil\"],\n",
    "    \"BGR\": [\"Bulgaria\"],\n",
    "    \"MEX\": [\"Mexico\"],\n",
    "    \"ROU\": [\"Romania\"],\n",
    "    \"ZAF\": [\"South Africa\"],\n",
    "    \"AUS\": [\"Australia\"],\n",
    "    \"BEL\": [\"Belgium\"],\n",
    "    \"DEU\": [\"Germany\", \"German Federal Republic\"],\n",
    "    \"ISR\": [\"Israel\"],\n",
    "    \"ITA\": [\"Italy\"],\n",
    "    \"JPN\": [\"Japan\"],\n",
    "    \"NZL\": [\"New Zealand\"],\n",
    "    \"GBR\": [\"United Kingdom\", \"Northern Ireland\"],\n",
    "    \"PRT\": [\"Portugal\"],\n",
    "    \"ESP\": [\"Spain\", \"Spain (Murcia)\"],\n",
    "    \"NLD\": [\"The Netherlands\", \"Netherlands\"],\n",
    "    \"USA\": [\"The USA\", \"USA\", \"United States of America\"]\n",
    "}\n",
    "\n",
    "# Here we're creating a function to standardize the names of our countries and regions to the target countries ISO code.\n",
    "# The function is referencing the countryScope dictionary allowing us to normalize the country name for merges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ACPOP': {'Ref Allele': 0.283, 'Alt Allele': 0.717, 'Expected Ref/Ref': 0.08008899999999998, 'Expected Alt/Alt': 0.5140889999999999, 'Expected Ref/Alt': 0.40582199999999996, 'HWE': 0.9999999999999998}, 'Africa': {'Ref Allele': 0.434, 'Alt Allele': 0.566, 'Expected Ref/Ref': 0.188356, 'Expected Alt/Alt': 0.3203559999999999, 'Expected Ref/Alt': 0.49128799999999995, 'HWE': 0.9999999999999999}, 'African': {'Ref Allele': 0.41395400000000004, 'Alt Allele': 0.5851824999999999, 'Expected Ref/Ref': 0.17135791411600004, 'Expected Alt/Alt': 0.3424385583062499, 'Expected Ref/Alt': 0.48447727321, 'HWE': 0.9982737456322499}, 'AfricanAmerican': {'Ref Allele': 0.41254, 'Alt Allele': 0.58746, 'Expected Ref/Ref': 0.1701892516, 'Expected Alt/Alt': 0.3451092516, 'Expected Ref/Alt': 0.4847014968, 'HWE': 1.0}, 'America': {'Ref Allele': 0.204, 'Alt Allele': 0.796, 'Expected Ref/Ref': 0.04161599999999999, 'Expected Alt/Alt': 0.6336160000000001, 'Expected Ref/Alt': 0.324768, 'HWE': 1.0}, 'American': {'Ref Allele': 0.3011775, 'Alt Allele': 0.6988224999999999, 'Expected Ref/Ref': 0.09070788650624999, 'Expected Alt/Alt': 0.48835288650624986, 'Expected Ref/Alt': 0.4209392269874999, 'HWE': 0.9999999999999998}, 'Ashkenazi Jewish': {'Ref Allele': 0.2726, 'Alt Allele': 0.7274, 'Expected Ref/Ref': 0.07431076, 'Expected Alt/Alt': 0.52911076, 'Expected Ref/Alt': 0.39657848, 'HWE': 1.0}, 'Asian': {'Ref Allele': 0.25026666666666664, 'Alt Allele': 0.7676000000000001, 'Expected Ref/Ref': 0.06263340444444443, 'Expected Alt/Alt': 0.5892097600000001, 'Expected Ref/Alt': 0.38420938666666665, 'HWE': 1.0360525511111112}, 'CRM': {'Ref Allele': 0.261, 'Alt Allele': 0.739, 'Expected Ref/Ref': 0.068121, 'Expected Alt/Alt': 0.546121, 'Expected Ref/Alt': 0.385758, 'HWE': 1.0}, 'CentralAmerican': {'Ref Allele': 0.3689, 'Alt Allele': 0.6311, 'Expected Ref/Ref': 0.13608721000000001, 'Expected Alt/Alt': 0.39828721, 'Expected Ref/Alt': 0.46562558, 'HWE': 1.0}, 'Central_South_Asia': {'Ref Allele': 0.36, 'Alt Allele': 0.64, 'Expected Ref/Ref': 0.1296, 'Expected Alt/Alt': 0.4096, 'Expected Ref/Alt': 0.4608, 'HWE': 1.0}, 'Cuban': {'Ref Allele': 0.3292, 'Alt Allele': 0.6708, 'Expected Ref/Ref': 0.10837263999999999, 'Expected Alt/Alt': 0.4499726399999999, 'Expected Ref/Alt': 0.44165471999999995, 'HWE': 0.9999999999999999}, 'Danish': {'Ref Allele': 0.25, 'Alt Allele': 0.75, 'Expected Ref/Ref': 0.0625, 'Expected Alt/Alt': 0.5625, 'Expected Ref/Alt': 0.375, 'HWE': 1.0}, 'Dominican': {'Ref Allele': 0.3573, 'Alt Allele': 0.6427, 'Expected Ref/Ref': 0.12766329, 'Expected Alt/Alt': 0.4130632900000001, 'Expected Ref/Alt': 0.45927342000000004, 'HWE': 1.0}, 'East Asian': {'Ref Allele': 0.2579666666666667, 'Alt Allele': 0.7420333333333332, 'Expected Ref/Ref': 0.06654680111111112, 'Expected Alt/Alt': 0.5506134677777776, 'Expected Ref/Alt': 0.3828397311111111, 'HWE': 0.9999999999999998}, 'Est_Asia': {'Ref Allele': 0.266, 'Alt Allele': 0.734, 'Expected Ref/Ref': 0.07075600000000001, 'Expected Alt/Alt': 0.538756, 'Expected Ref/Alt': 0.390488, 'HWE': 1.0}, 'Estonian': {'Ref Allele': 0.2612, 'Alt Allele': 0.7388, 'Expected Ref/Ref': 0.06822544, 'Expected Alt/Alt': 0.54582544, 'Expected Ref/Alt': 0.38594912, 'HWE': 1.0}, 'Europe': {'Ref Allele': 0.32372500000000004, 'Alt Allele': 0.6762750000000001, 'Expected Ref/Ref': 0.10479787562500002, 'Expected Alt/Alt': 0.4573478756250001, 'Expected Ref/Alt': 0.4378542487500001, 'HWE': 1.0000000000000002}, 'European': {'Ref Allele': 0.29334000000000005, 'Alt Allele': 0.71219, 'Expected Ref/Ref': 0.08604835560000003, 'Expected Alt/Alt': 0.5072145961, 'Expected Ref/Alt': 0.41782762920000005, 'HWE': 1.0110905809}, 'Genome of the Netherlands': {'Ref Allele': 0.32, 'Alt Allele': 0.68, 'Expected Ref/Ref': 0.1024, 'Expected Alt/Alt': 0.4624000000000001, 'Expected Ref/Alt': 0.43520000000000003, 'HWE': 1.0}, 'Global': {'Ref Allele': 0.3045544615384616, 'Alt Allele': 0.6954455384615384, 'Expected Ref/Ref': 0.09275342004298229, 'Expected Alt/Alt': 0.48364449696605916, 'Expected Ref/Alt': 0.4236020829909587, 'HWE': 1.0}, 'JAPANESE': {'Ref Allele': 0.22582, 'Alt Allele': 0.77418, 'Expected Ref/Ref': 0.050994672399999996, 'Expected Alt/Alt': 0.5993546724, 'Expected Ref/Alt': 0.3496506552, 'HWE': 1.0}, 'KOREAN': {'Ref Allele': 0.23804999999999998, 'Alt Allele': 0.76195, 'Expected Ref/Ref': 0.05666780249999999, 'Expected Alt/Alt': 0.5805678025000001, 'Expected Ref/Alt': 0.36276439499999996, 'HWE': 1.0}, 'Mexican': {'Ref Allele': 0.31281, 'Alt Allele': 0.68719, 'Expected Ref/Ref': 0.09785009609999999, 'Expected Alt/Alt': 0.47223009609999994, 'Expected Ref/Alt': 0.42991980779999994, 'HWE': 0.9999999999999999}, 'Middle_Est': {'Ref Allele': 0.362, 'Alt Allele': 0.638, 'Expected Ref/Ref': 0.131044, 'Expected Alt/Alt': 0.407044, 'Expected Ref/Alt': 0.461912, 'HWE': 1.0}, 'NativeAmerican': {'Ref Allele': 0.3048, 'Alt Allele': 0.6952, 'Expected Ref/Ref': 0.09290304, 'Expected Alt/Alt': 0.4833030400000001, 'Expected Ref/Alt': 0.42379392000000005, 'HWE': 1.0}, 'NativeHawaiian': {'Ref Allele': 0.3994, 'Alt Allele': 0.6006, 'Expected Ref/Ref': 0.15952035999999997, 'Expected Alt/Alt': 0.36072036, 'Expected Ref/Alt': 0.47975928, 'HWE': 1.0}, 'Oceania': {'Ref Allele': 0.49, 'Alt Allele': 0.51, 'Expected Ref/Ref': 0.24009999999999998, 'Expected Alt/Alt': 0.2601, 'Expected Ref/Alt': 0.4998, 'HWE': 1.0}, 'Other': {'Ref Allele': 0.33625, 'Alt Allele': 0.6558, 'Expected Ref/Ref': 0.11306406249999999, 'Expected Alt/Alt': 0.4300736400000001, 'Expected Ref/Alt': 0.4410255, 'HWE': 0.9841632025}, 'PARENT AND CHILD COHORT': {'Ref Allele': 0.3036, 'Alt Allele': 0.6964, 'Expected Ref/Ref': 0.09217295999999998, 'Expected Alt/Alt': 0.48497296, 'Expected Ref/Alt': 0.42285407999999997, 'HWE': 1.0}, 'PuertoRican': {'Ref Allele': 0.3374, 'Alt Allele': 0.6626, 'Expected Ref/Ref': 0.11383875999999998, 'Expected Alt/Alt': 0.43903876, 'Expected Ref/Alt': 0.44712247999999993, 'HWE': 1.0}, 'South Asian': {'Ref Allele': 0.32983333333333337, 'Alt Allele': 0.6717, 'Expected Ref/Ref': 0.1087900277777778, 'Expected Alt/Alt': 0.45118088999999995, 'Expected Ref/Alt': 0.4430981, 'HWE': 1.0030690177777777}, 'SouthAmerican': {'Ref Allele': 0.3153, 'Alt Allele': 0.6847, 'Expected Ref/Ref': 0.09941409000000001, 'Expected Alt/Alt': 0.46881408999999996, 'Expected Ref/Alt': 0.43177182000000003, 'HWE': 1.0}, 'SouthAsian': {'Ref Allele': 0.329, 'Alt Allele': 0.671, 'Expected Ref/Ref': 0.108241, 'Expected Alt/Alt': 0.45024100000000006, 'Expected Ref/Alt': 0.441518, 'HWE': 1.0}, 'TWIN COHORT': {'Ref Allele': 0.308, 'Alt Allele': 0.692, 'Expected Ref/Ref': 0.094864, 'Expected Alt/Alt': 0.47886399999999996, 'Expected Ref/Alt': 0.426272, 'HWE': 1.0}}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "class Countryparser:\n",
    "    def standardizeCountryName(data_Frame, country_Col, countryScope):\n",
    "        # Creating an empty dictionary who's key is the country name, and who's value is the corresponding ISO code.\n",
    "        standardizedCountries = {}\n",
    "        # This loops through each key-value pair in the country_scope dictionary. iso_code is the key (the ISO country code), and names is the value (a list of country names).\n",
    "        for iso_Code, names in countryScope.items():\n",
    "            for name in names:\n",
    "                standardizedCountries[name] = iso_Code\n",
    "        # This maps the country names in the specified column of the DataFrame to their corresponding ISO codes using the standardized_countries dictionary.\n",
    "        # The .fillna() method in this this case ensures that any country name not found in the countryScope remains unchanged.\n",
    "        data_Frame[country_Col] = data_Frame[country_Col].map(standardizedCountries).fillna(data_Frame[country_Col])\n",
    "        return data_Frame\n",
    "\n",
    "\n",
    "class Bioparser:\n",
    "    @staticmethod\n",
    "    def splitAlleleToDict(data_Frame, ref_allele_col='Ref Allele', alt_allele_col='Alt Allele', population_col='Population'):\n",
    "        def splitAllele(allele):\n",
    "            try:\n",
    "                letter, value = allele.split('=', 1)\n",
    "                return letter, float(value)\n",
    "            except ValueError:\n",
    "                return allele, None  # Handle unexpected formats\n",
    "\n",
    "        # Apply the function to split 'Ref Allele' and 'Alt Allele'\n",
    "        data_Frame[['Ref Allele Letter', 'Ref Allele Value']\n",
    "                   ] = data_Frame[ref_allele_col].apply(splitAllele).tolist()\n",
    "        data_Frame[['Alt Allele Letter', 'Alt Allele Value']\n",
    "                   ] = data_Frame[alt_allele_col].apply(splitAllele).tolist()\n",
    "\n",
    "        # Drop the original 'Ref Allele' and 'Alt Allele' columns\n",
    "        data_Frame = data_Frame.drop(columns=[ref_allele_col, alt_allele_col])\n",
    "\n",
    "        # Initialize the dictionary\n",
    "        populationAlleleFrequency = {}\n",
    "        populationAlleleFrequency = {}\n",
    "        populationAlleleFrequency = {}\n",
    "        populationAlleleFrequency = {}\n",
    "\n",
    "        # Group by 'Population' and calculate the mean of 'Ref Allele Value' and 'Alt Allele Value'\n",
    "        allele_grouped = data_Frame.groupby([population_col]).agg({\n",
    "            'Ref Allele Value': 'mean',\n",
    "            'Alt Allele Value': 'mean'\n",
    "        }).reset_index()\n",
    "\n",
    "        # Calculate genotype frequencies using Hardy-Weinberg equilibrium and populate the dictionary\n",
    "        for _, row in allele_grouped.iterrows():\n",
    "            population = row[population_col]\n",
    "            p = row['Ref Allele Value']\n",
    "            q = row['Alt Allele Value']\n",
    "\n",
    "            if pd.notna(p) and pd.notna(q):\n",
    "                ref_ref = p ** 2\n",
    "                alt_alt = q ** 2\n",
    "                ref_alt = 2 * p * q\n",
    "\n",
    "                hwe = ref_ref + alt_alt + ref_alt\n",
    "\n",
    "                populationAlleleFrequency[population] = {\n",
    "                    'Ref Allele': p,\n",
    "                    'Alt Allele': q,\n",
    "                    'Expected Ref/Ref': ref_ref,\n",
    "                    'Expected Alt/Alt': alt_alt,\n",
    "                    'Expected Ref/Alt': ref_alt,\n",
    "                    'HWE': hwe\n",
    "                }\n",
    "        return populationAlleleFrequency\n",
    "\n",
    "\n",
    "# Example usage\n",
    "result = Bioparser.splitAlleleToDict(rs1360780Data)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applied Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference Notes\n",
    "1. Declaring comments within each CSV via the `comment=` command.\n",
    "2. TSV files can be read via the CSV reader, however they must delineate that the columns are separated by tabs rather than commas via the `sep='\\t'` command. Likewise we are skipping the first 12 rows of the referenced file due to the odd file structure and are setting the header to the index of line we just skipped, which in our case would be 0.\n",
    "3. CSV parameter low memory was set to false in order to resolve mixed type issue occurring due to file being processed in chunks rather than a whole."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
